---
######Article 1################################
title: "An example journal article 2"
authors:
- admin
- Merten Stender
- Sudeshna Sinha
author_notes:
- "Equal contribution"
- "Equal contribution"
date: "2015-09-01T00:00:00Z"

# Schedule page publish date (NOT publication's date).
publishDate: "2017-01-01T00:00:00Z"

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
publication_types: ["article-journal"]

# Publication name and optional abbreviated publication name.
publication: "*Journal of Source Themes, 1*(1)"
publication_short: ""

abstract: Lorem ipsumibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.

# Summary. An optional shortened abstract.
summary: In the quest to understand the   structure-function relationship of networks, scientists ended-up developing a new method for designing efficient networks that solve complex tasks with fewer nodes and greater efficiency, by allowing networks to grow and shrink based on performance, outperforming traditional random networks and other common growth strategies. The study introduces a novel performance-dependent network evolution framework, where networks dynamically add or remove nodes depending on how well they solve a given task [1]. This results in smaller, more specialized structures optimized for specific types of information processing, following unique scaling laws and node distributions. The proposed framework has been tested on reservoir computers, a machine-learning model with three layers: input, reservoir, and output. The input layer maps data into the reservoir, a fixed high-dimensional dynamical system, while only the output layer is trained, making the system computationally efficient by tuning just this layer instead of the entire network.
  Unlike conventional reservoir networks, which often require extensive tuning, these evolved reservoir networks naturally develop minimal structures that achieve high performance with fewer nodes. The study found that networks solving simple tasks, such as sine-to-cosine mapping, tend to be smaller and denser, while more complex tasks, like chaotic time-series prediction, require larger networks but remain efficient. This reveals a clear relationship between network size, density, and task complexity, leading to one of the study's key contributions: a new method to quantify task complexity by analyzing the self-organization of evolved networks in the parametric space of network size and density. 
  
  Additionally, evolved networks exhibit a distinctive asymmetry in the distribution of input and readout nodes. This mirrors biological systems, where networks prioritize extracting and processing information efficiently.
  This work has broad implications for fields like network science, reservoir computing, machine learning, and neuroscience. By revealing the underlying principles of task-specific network growth, it provides a powerful framework for designing more efficient and adaptable computational networks. This could lead to smaller, faster, and more specialized AI systems, as well as provide deeper insights into how biological networks evolve to process complex information.


tags:
- Source Themes
featured: True

hugoblox:
  ids:
    arxiv: 1512.04133v1

links:
  - type: pdf
    url: http://arxiv.org/pdf/1512.04133v1
  - type: code
    url: https://github.com/HugoBlox/hugo-blox-builder
  - type: dataset
    url: ""
  - type: poster
    url: ""
  - type: project
    url: ""
  - type: slides
    url: https://www.slideshare.net/
  - type: source
    url: ""
  - type: video
    url: ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  caption: author
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""

######Article 2##########################################


---

> [!NOTE]
> Click the *Cite* button above to demo the feature to enable visitors to import publication metadata into their reference management software.

> [!NOTE]
> Create your slides in Markdown - click the *Slides* button to check out the example.

Add the publication's **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/).


